@inproceedings{wei2022chain,
  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{xu2026language,
  title={Language of Thought Shapes Output Diversity in Large Language Models},
  author={Xu, Hanqi and Zhang, Yining},
  journal={arXiv preprint arXiv:2601.11227},
  year={2026}
}

@article{jain2025homogenization,
  title={{LLM} Output Homogenization is Task Dependent},
  author={Jain, Nishant and others},
  journal={arXiv preprint arXiv:2509.21267},
  year={2025}
}

@inproceedings{turpin2023language,
  title={Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting},
  author={Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel R},
  booktitle={Advances in Neural Information Processing Systems},
  year={2023}
}

@article{chen2025reasoning,
  title={Reasoning Models Don't Always Say What They Think},
  author={Chen, Yanda and others},
  journal={arXiv preprint arXiv:2505.05410},
  year={2025}
}

@article{afzal2025knowing,
  title={Knowing Before Saying: {LLM} Representations Encode Chain-of-Thought Success Before Completion},
  author={Afzal, Syed Adnan and others},
  journal={arXiv preprint arXiv:2505.24362},
  year={2025}
}

@article{wenger2025creative,
  title={We're Different, We're the Same: Creative Homogeneity Across {LLMs}},
  author={Wenger, Mika and Kenett, Yoed N},
  journal={arXiv preprint arXiv:2501.19361},
  year={2025}
}

@article{mirka2025homogenizing,
  title={The Homogenizing Effect of Large Language Models on Human Expression and Thought},
  author={Mirka, Benedikt and others},
  journal={arXiv preprint arXiv:2508.01491},
  year={2025}
}

@inproceedings{suzgun2023challenging,
  title={Challenging {BIG}-Bench Tasks and Whether Chain-of-Thought Can Solve Them},
  author={Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and Wei, Jason},
  booktitle={Findings of the Association for Computational Linguistics: ACL},
  year={2023}
}

@inproceedings{reimers2019sentencebert,
  title={Sentence-{BERT}: Sentence Embeddings using Siamese {BERT}-Networks},
  author={Reimers, Nils and Gurevych, Iryna},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing},
  year={2019}
}

@article{kojima2022large,
  title={Large Language Models are Zero-Shot Reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{wang2023selfconsistency,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc V and Chi, Ed H and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2023}
}
